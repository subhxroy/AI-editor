
import { GoogleGenAI, Modality, GenerateContentResponse } from "@google/genai";
import { OptimizedPrompt } from '../types';

if (!process.env.API_KEY) {
    throw new Error("API_KEY environment variable is not set");
}

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
const promptOptimizerModel = "gemini-2.5-flash";
const imageEditModel = "gemini-2.5-flash-image";

const PROMPT_OPTIMIZER_SYSTEM_INSTRUCTION = `SYSTEM: You are an expert image-prompt engineer. Your job is to take a user's casual edit request and produce a high-quality, concise prompt for an image-edit model (gemini-2.5-flash-image). Also produce structured metadata to control the image edit (aspect ratio, style tags, lighting, color grade, camera/lens, negative prompts, mask hints, strength 0.0–1.0, num_variants). Output only valid JSON.

INSTRUCTIONS:
1. Rewrite the USER_PROMPT into field "prompt" — 1–2 sentences, concrete, descriptive, no fluff.
2. Add "style" tags (max 6) and a single short "reference" phrase (e.g., 'film noir, Kodak Portra, painterly, cyberpunk').
3. Provide "camera" and "lighting" lines if user mentions photographic realism.
4. Provide "negative_prompts" (things to avoid).
5. Suggest "mask_hint" if the edit targets a sub-region (e.g., 'select face and shoulders; leave background intact').
6. Choose "strength" (0.0–1.0) for how strongly to change the image; default 0.6.
7. Suggest "aspect_ratio" (e.g., '4:5' for portrait, '16:9' for landscape).
8. Provide "num_variants" (1–4). Default to 3.
9. Keep each field concise and machine-friendly.

OUTPUT JSON SCHEMA:
{
  "prompt": string,
  "style": [string],
  "reference": string,
  "camera": string|null,
  "lighting": string|null,
  "color_grade": string|null,
  "negative_prompts": string,
  "mask_hint": string|null,
  "strength": number,
  "aspect_ratio": string,
  "num_variants": integer,
  "notes": string (brief, optional)
}`;

export const optimizePrompt = async (userPrompt: string): Promise<OptimizedPrompt> => {
    try {
        const response = await ai.models.generateContent({
            model: promptOptimizerModel,
            contents: `USER_PROMPT: "${userPrompt}"`,
            config: {
                systemInstruction: PROMPT_OPTIMIZER_SYSTEM_INSTRUCTION,
                responseMimeType: "application/json",
            }
        });

        const text = response.text.trim();
        return JSON.parse(text) as OptimizedPrompt;
    } catch (error) {
        console.error("Error optimizing prompt:", error);
        throw new Error("Failed to get a valid editing plan from the AI. Please try rephrasing your request.");
    }
};

export const editImage = async (
    imageDataUrl: string,
    mimeType: string,
    prompt: string
): Promise<string> => {
    try {
        const base64Data = imageDataUrl.split(',')[1];
        if (!base64Data) {
            throw new Error("Invalid image data URL");
        }

        const response: GenerateContentResponse = await ai.models.generateContent({
            model: imageEditModel,
            contents: {
                parts: [
                    { inlineData: { data: base64Data, mimeType: mimeType } },
                    { text: prompt },
                ],
            },
            config: {
                responseModalities: [Modality.IMAGE],
            },
        });
        
        const imagePart = response.candidates?.[0]?.content?.parts?.find(part => part.inlineData);

        if (imagePart && imagePart.inlineData) {
            const newBase64 = imagePart.inlineData.data;
            return `data:${imagePart.inlineData.mimeType};base64,${newBase64}`;
        }

        throw new Error("No image was generated by the model.");

    } catch (error) {
        console.error("Error editing image:", error);
        throw new Error("The image editing process failed. The model may have refused the request due to safety policies.");
    }
};
